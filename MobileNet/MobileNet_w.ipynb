{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/jankiemm/anaconda3/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/jankiemm/anaconda3/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c106detail19maybe_wrap_dim_slowIxEET_S2_S2_b\n",
            "  Referenced from: <9B280146-BBD7-3F77-9873-F9740F2A5329> /Users/jankiemm/anaconda3/lib/python3.10/site-packages/torchvision/image.so\n",
            "  Expected in:     <FB753559-B5BA-3279-8C4E-2AB6619F0AE9> /Users/jankiemm/anaconda3/lib/python3.10/site-packages/torch/lib/libc10.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
            "  warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchviz in /Users/jankiemm/anaconda3/lib/python3.10/site-packages (0.0.2)\n",
            "Requirement already satisfied: torch in /Users/jankiemm/anaconda3/lib/python3.10/site-packages (from torchviz) (1.12.1)\n",
            "Requirement already satisfied: graphviz in /Users/jankiemm/anaconda3/lib/python3.10/site-packages (from torchviz) (0.20.1)\n",
            "Requirement already satisfied: typing_extensions in /Users/jankiemm/anaconda3/lib/python3.10/site-packages (from torch->torchviz) (4.4.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "import torch                                          #Line 1\n",
        "import torchvision.models as models                   #Line 2\n",
        "from PIL import Image                                 #Line 3\n",
        "import torchvision.transforms.functional as TF        #Line 4\n",
        "from torchinfo import summary                      #Line 5\n",
        "%pip install torchviz                                 #Line 6\n",
        "from torchviz import make_dot                         #Line 7\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')                                                      #LINE 0\n",
        "mobilenet_pretrained = models.mobilenet_v2(pretrained=False).to(device)   \n",
        "                                                             #LINE 1\n",
        "summary(mobilenet_pretrained)                    #LINE 2\n",
        "#resnet_pretrained  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 3, 224, 224])\n"
          ]
        }
      ],
      "source": [
        "image = Image.open('cup.webp')   #Line 8\n",
        "image=image.resize((224,224))       #Line 9\n",
        "x = TF.to_tensor(image)             #Line 10\n",
        "x.unsqueeze_(0)                     #Line 11\n",
        "x=x.to(device)                      #Line 12\n",
        "print(x.shape)                      #Line 13"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "858"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mobilenet_prediction=mobilenet_pretrained(x)                       #Line 4\n",
        "mobilenet_prediction_numpy=mobilenet_prediction.detach().numpy()   #Line 5\n",
        "predicted_class_max = np.argmax(mobilenet_prediction_numpy)     #Line 6\n",
        "predicted_class_max       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "MobileNet.ipynb",
      "provenance": [],
      "version": "0.3.2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
